{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfdb7ec8",
   "metadata": {},
   "source": [
    "### Intall dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7fa983",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers spacy nltk\n",
    "python -m spacy download en_core_web_sm (bash command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8526ea",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95b4e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import spacy\n",
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bd7913",
   "metadata": {},
   "source": [
    "#### transformers: This library provides pre-trained models for natural language processing tasks. In this case, we use it to load the GPT-2 language model.\n",
    "#### GPT2LMHeadModel: GPT-2 language model from the transformers library.\n",
    "#### GPT2Tokenizer: Tokenizer specific to the GPT-2 model.\n",
    "#### spacy: A library for natural language processing. We use it here for sentence tokenization.\n",
    "#### sent_tokenize: A function from NLTK (Natural Language Toolkit) for sentence tokenization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2996336c",
   "metadata": {},
   "source": [
    "### Sentence Tokenization Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8a4f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentences(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    return [sent.text for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd750e57",
   "metadata": {},
   "source": [
    "#### tokenize_sentences: A function that takes a text input and tokenizes it into sentences using the spaCy library. The en_core_web_sm model is a small English model provided by spaCy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d54950",
   "metadata": {},
   "source": [
    "### Chatbot Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cf5e5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_gpt2(prompt, max_length=100):\n",
    "    model_name = \"gpt2\"\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "    sentences = tokenize_sentences(prompt)\n",
    "    responses = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        input_ids = tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "        output = model.generate(input_ids, max_length=max_length, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95)\n",
    "\n",
    "        response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        responses.append(response)\n",
    "\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be20fc8a",
   "metadata": {},
   "source": [
    "#### chat_with_gpt2: The main function for interacting with the GPT-2 model. It takes a user prompt, tokenizes it into sentences, and generates a response for each sentence using the GPT-2 model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4dc441",
   "metadata": {},
   "source": [
    "### User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6abb40d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot Responses:\n",
      "Bot: Can you tell me a joke?\n",
      "\n",
      "I don't know. I'm not going to tell you that. But I do know that it's funny. It's a funny thing to do, and I think that's what makes it so funny, because you know what I mean? I've been doing it for a long time. And I love it. So, I guess I'll just say it again, but I just want to make sure that you're aware of what's going on\n",
      "Bot: Also, what's the weather like today?\n",
      "\n",
      "The weather is a bit different today than it was a few days ago, but it's still pretty good. It's not as cold as it used to be, and there's a lot of snow on the ground. There's also a little bit of rain, which is nice. I think we're going to see more snow in the next couple of days, so we'll see how that plays out. We've got to keep an eye\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Can you tell me a joke? Also, what's the weather like today?\"\n",
    "bot_responses = chat_with_gpt2(user_input)\n",
    "print(\"Bot Responses:\")\n",
    "for response in bot_responses:\n",
    "    print(\"Bot:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7b8f3a",
   "metadata": {},
   "source": [
    "#### user_input: A string containing the user's input or prompt.\n",
    "#### bot_responses: A list of responses generated by the chatbot for each sentence in the input.\n",
    "#### Printing the bot's responses for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9bf301c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot Responses:\n",
      "Bot: Can you tell me about Natural Language Processing in computers?\n",
      "\n",
      "Natural language processing (NLP) is the process by which a computer learns to recognize a word or phrase. NLP is a process that involves the processing of words and phrases in a way that allows the computer to understand the meaning of those words or phrases. The process is called \"learning\" or \"processing\" and is often referred to as \"machine learning\".\n",
      ". Natural language learning (NNL) refers to the ability of\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Can you tell me about Natural Language Processing in computers\"\n",
    "bot_responses = chat_with_gpt2(user_input)\n",
    "print(\"Bot Responses:\")\n",
    "for response in bot_responses:\n",
    "    print(\"Bot:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495fb022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
