{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "698585b5",
   "metadata": {},
   "source": [
    "pandas is used for handling data frames and goose3 is a library for extracting information from web pages.<br>\n",
    "It reads a the CSV file named \"input.csv\" (coverted into csv form xlsx) using pandas and stores it.<br>\n",
    "A Goose instance (g) is created. This instance is used to extract information from web pages.<br>\n",
    "The function extract_article is defined that takes a URL as input, uses the goose instance to extract information (title and cleaned text) from the web page, and returns the title and text.<br>\n",
    "It iterates through each row in the DataFrame (df). It extracts the 'URL_ID' and 'URL' from each row.<br>\n",
    "Inside the loop, it tries to extract the article's title and text using the extract_article function.<br>\n",
    "If successful, it creates a text file named \"{url_id}.txt\" and writes the title and text into it.<br>\n",
    "If there is an exception (error), it prints an error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23c913fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article extracted and saved for URL_ID: blackassign0001\n",
      "Article extracted and saved for URL_ID: blackassign0002\n",
      "Article extracted and saved for URL_ID: blackassign0003\n",
      "Article extracted and saved for URL_ID: blackassign0004\n",
      "Article extracted and saved for URL_ID: blackassign0005\n",
      "Article extracted and saved for URL_ID: blackassign0006\n",
      "Article extracted and saved for URL_ID: blackassign0007\n",
      "Article extracted and saved for URL_ID: blackassign0008\n",
      "Article extracted and saved for URL_ID: blackassign0009\n",
      "Article extracted and saved for URL_ID: blackassign0010\n",
      "Article extracted and saved for URL_ID: blackassign0011\n",
      "Article extracted and saved for URL_ID: blackassign0012\n",
      "Article extracted and saved for URL_ID: blackassign0013\n",
      "Article extracted and saved for URL_ID: blackassign0014\n",
      "Article extracted and saved for URL_ID: blackassign0015\n",
      "Article extracted and saved for URL_ID: blackassign0016\n",
      "Article extracted and saved for URL_ID: blackassign0017\n",
      "Article extracted and saved for URL_ID: blackassign0018\n",
      "Article extracted and saved for URL_ID: blackassign0019\n",
      "Article extracted and saved for URL_ID: blackassign0020\n",
      "Article extracted and saved for URL_ID: blackassign0021\n",
      "Article extracted and saved for URL_ID: blackassign0022\n",
      "Article extracted and saved for URL_ID: blackassign0023\n",
      "Article extracted and saved for URL_ID: blackassign0024\n",
      "Article extracted and saved for URL_ID: blackassign0025\n",
      "Article extracted and saved for URL_ID: blackassign0026\n",
      "Article extracted and saved for URL_ID: blackassign0027\n",
      "Article extracted and saved for URL_ID: blackassign0028\n",
      "Article extracted and saved for URL_ID: blackassign0029\n",
      "Article extracted and saved for URL_ID: blackassign0030\n",
      "Article extracted and saved for URL_ID: blackassign0031\n",
      "Article extracted and saved for URL_ID: blackassign0032\n",
      "Article extracted and saved for URL_ID: blackassign0033\n",
      "Article extracted and saved for URL_ID: blackassign0034\n",
      "Article extracted and saved for URL_ID: blackassign0035\n",
      "Error processing URL_ID blackassign0036: NetworkError: status code: Not Found; reason: 404\n",
      "Article extracted and saved for URL_ID: blackassign0037\n",
      "Article extracted and saved for URL_ID: blackassign0038\n",
      "Article extracted and saved for URL_ID: blackassign0039\n",
      "Article extracted and saved for URL_ID: blackassign0040\n",
      "Article extracted and saved for URL_ID: blackassign0041\n",
      "Article extracted and saved for URL_ID: blackassign0042\n",
      "Article extracted and saved for URL_ID: blackassign0043\n",
      "Article extracted and saved for URL_ID: blackassign0044\n",
      "Article extracted and saved for URL_ID: blackassign0045\n",
      "Article extracted and saved for URL_ID: blackassign0046\n",
      "Article extracted and saved for URL_ID: blackassign0047\n",
      "Article extracted and saved for URL_ID: blackassign0048\n",
      "Error processing URL_ID blackassign0049: NetworkError: status code: Not Found; reason: 404\n",
      "Article extracted and saved for URL_ID: blackassign0050\n",
      "Article extracted and saved for URL_ID: blackassign0051\n",
      "Article extracted and saved for URL_ID: blackassign0052\n",
      "Article extracted and saved for URL_ID: blackassign0053\n",
      "Article extracted and saved for URL_ID: blackassign0054\n",
      "Article extracted and saved for URL_ID: blackassign0055\n",
      "Article extracted and saved for URL_ID: blackassign0056\n",
      "Article extracted and saved for URL_ID: blackassign0057\n",
      "Article extracted and saved for URL_ID: blackassign0058\n",
      "Article extracted and saved for URL_ID: blackassign0059\n",
      "Article extracted and saved for URL_ID: blackassign0060\n",
      "Article extracted and saved for URL_ID: blackassign0061\n",
      "Article extracted and saved for URL_ID: blackassign0062\n",
      "Article extracted and saved for URL_ID: blackassign0063\n",
      "Article extracted and saved for URL_ID: blackassign0064\n",
      "Article extracted and saved for URL_ID: blackassign0065\n",
      "Article extracted and saved for URL_ID: blackassign0066\n",
      "Article extracted and saved for URL_ID: blackassign0067\n",
      "Article extracted and saved for URL_ID: blackassign0068\n",
      "Article extracted and saved for URL_ID: blackassign0069\n",
      "Article extracted and saved for URL_ID: blackassign0070\n",
      "Article extracted and saved for URL_ID: blackassign0071\n",
      "Article extracted and saved for URL_ID: blackassign0072\n",
      "Article extracted and saved for URL_ID: blackassign0073\n",
      "Article extracted and saved for URL_ID: blackassign0074\n",
      "Article extracted and saved for URL_ID: blackassign0075\n",
      "Article extracted and saved for URL_ID: blackassign0076\n",
      "Article extracted and saved for URL_ID: blackassign0077\n",
      "Article extracted and saved for URL_ID: blackassign0078\n",
      "Article extracted and saved for URL_ID: blackassign0079\n",
      "Article extracted and saved for URL_ID: blackassign0080\n",
      "Article extracted and saved for URL_ID: blackassign0081\n",
      "Article extracted and saved for URL_ID: blackassign0082\n",
      "Article extracted and saved for URL_ID: blackassign0083\n",
      "Article extracted and saved for URL_ID: blackassign0084\n",
      "Article extracted and saved for URL_ID: blackassign0085\n",
      "Article extracted and saved for URL_ID: blackassign0086\n",
      "Article extracted and saved for URL_ID: blackassign0087\n",
      "Article extracted and saved for URL_ID: blackassign0088\n",
      "Article extracted and saved for URL_ID: blackassign0089\n",
      "Article extracted and saved for URL_ID: blackassign0090\n",
      "Article extracted and saved for URL_ID: blackassign0091\n",
      "Article extracted and saved for URL_ID: blackassign0092\n",
      "Article extracted and saved for URL_ID: blackassign0093\n",
      "Article extracted and saved for URL_ID: blackassign0094\n",
      "Article extracted and saved for URL_ID: blackassign0095\n",
      "Article extracted and saved for URL_ID: blackassign0096\n",
      "Article extracted and saved for URL_ID: blackassign0097\n",
      "Article extracted and saved for URL_ID: blackassign0098\n",
      "Article extracted and saved for URL_ID: blackassign0099\n",
      "Article extracted and saved for URL_ID: blackassign0100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from goose3 import Goose\n",
    "csv_file = \"input.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "g = Goose() # Create a Goose instance\n",
    "def extract_article(url):\n",
    "    article = g.extract(url)\n",
    "    title = article.title\n",
    "    text = article.cleaned_text\n",
    "    return title, text\n",
    "for index, row in df.iterrows():\n",
    "    url_id = row['URL_ID']\n",
    "    url = row['URL']\n",
    "    try:\n",
    "        title, text = extract_article(url)\n",
    "        output_file = f\"{url_id}.txt\"\n",
    "        with open(output_file, 'w', encoding='utf-8') as file:\n",
    "            file.write(f\"Title: {title}\\n\\n{text}\")\n",
    "        print(f\"Article extracted and saved for URL_ID: {url_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL_ID {url_id}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca45f72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
